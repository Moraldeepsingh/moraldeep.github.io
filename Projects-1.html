<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Moraldeep's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/profile_pic2.jpeg" alt="" /></a>
					<h1><strong>Hello, I am Moraldeep</strong><br /></h1>
					</h2><br /> 
					<strong>My Projects have had a keen focus on</strong><br />
					Data Visualization<br />
					Supply Chain and Lean Principles <br />
					Image Processing<br />
					Statistics<br />
					Natural Language Processing<br />
					<br /><br />
					<ul class="links"><li><a href="index.html">HomePage</a></li></ul>
					
					
					
					<!-- Main 
					<a href="http://html5up.net">HTML5 UP </a>.</h2><br /><br />
				-->
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
							<h1 style="text-align: center"> <u><strong>Projects </strong>   </u>  </h1>
							<!-- <h2 style="text-align: center;font-size:35px">Analytics | Supply Chain | Product Management Enthusiast</h2> -->
							<!-- <p style="color:grey;text-align:left; font-size:18px">
								<a href="images/mytransition2.svg" class="image"></a><img src="images/mytransition2.svg" alt="" /></a>
								<!-- One 
								<ul class="actions"> -->
								
								<!-- </ul>
								--> 




								<!--
								Skillset: </br>						
							• Tech Skills: R, Python, SQL, Google Analytics, MATLAB, Microsoft Excel/VBA<br />
							• Financial Modeling: Times Series, Monte Carlo Simulation, Stochastic Process<br />
							• Statistics: Machine Learning, Advanced Data Analysis<br />
							• Experiences: Predictive Modeling, Classification, Segmentation, A/B Testing, Time Series Analysis, Web Crawling, NLP, Visualization<br />
							
							</p>
							</header>
						
						<p>I believe in maximizing efficiency in everything I do and that has led me to opt for Industrial Engineering and Operations Research - the science of optimization. After completing my studies in Mechanical Engineering from VIT University, Vellore, I wanted to bridge the gap between the Theoretical and practical aspects and use analytics and Mathematical modelling skills to solve real-world problems such as Supply chain Management and Inventory Control issues in Industry. <br /><br />

							I have a strong background in Optimization, Mathematical modeling, quantitative analysis, Machine learning, Game theory and experience of working with languages such as Python, R along with a touch of Hardcore Industry Experience with pioneering automobile Manufacturers in India such as Mercedes Benz India Pvt Ltd and Mahindra and Mahindra. <br /> <br />
							
							When not solving real-world Industry problems, I like to work for social causes like Blood Donation for the betterment of society and I am proud to say that my team Youth Red Cross VIT handled over 200 Emergency cases in CMC Hospital Vellore in the calendar year of 2017.</p>
						<ul class="actions">
							<li><a href="#" class="button">Learn More</a></li>
						</ul>
					</section>
						-->
				<!-- Two -->
			

					<section id="two">
						<h2 >1. Pedestrian Intention Prediction</h2>
						<!-- <h2 style="font-size: smaller">Master of Engineering in Industrial Engineering and Operations Research (August 2019 to December 2020)</h2> -->
						<div class="row">
							<article class="col-6 col-12-xsmall work-item">
								<img src="images/Project_Images/modelA.gif" alt="Beam_1" style="width:489px;height326px;">
								<img src="images/Project_Images/modelC.gif" alt="Beam_1" style="width:489px;height326px;">
								</div>
								<!-- <a href="#" class="image"><img src="images/Work_Images/Beam_1.jpg" style="width:489px;height:326px alt=" /></a> -->
								<!-- <ul class="images"><li><a href="Website Project/Work Experience.html">Work Experience</a></li></ul> -->
								</article>
							<!-- <article class="col-6 col-12-xsmall work-item">
								<img src="images/Work_Images/Beam_2.jpg" alt="Beam_2" style="width:489px;height326px;">
								 <a href="#" class="image"><img src="images/Work_Images/Beam_2.jpg" style="width:500px;height:600px alt=" /></a> -->
								<!-- <h3>Projects</h3> -->
								<p></p>
							</article>
							
							<p style="font-family: Arial, Helvetica, sans-serif; color: black;">
								
								
								Brief Project description:</br></br>
								<ul class="links"><li><a href="https://github.com/mjpramirez/Volvo-DataX">Github Repo</a></li></ul>
								<ul class="links"><li><a href="https://matthew29tang.github.io/pid-model/#/">Project Website</a></li></ul>
								<ul class="links"><li><a href="https://arxiv.org/abs/2005.07796">Research Paper at arXiv</a></li></ul>
							
								Collaborative research project between Volvo Cars, 
								and student teams from UC Berkeley and Chalmers University.</br></br>

								The research project was aimed at predicting the intention of a pedestrian 
								to cross or not cross the road. This project was a successful attempt to 
								emulate the behavior of a human driver to guess the intention of fellow road 
								users such as pedestrians. Our team based the approach on a research paper that 
								had some progress in this line of work. After replicating the paper, our teams 
								decided on experimenting additional approaches and eventually arrived at Fusion 
								based Intention Prediction Networks.</br></br>

								First Model that we built was based on the research paper. 
								This model consisted of 3 components: Object detector, object tracker, 
								and a classifier. The model predicted the intention of pedestrians to cross
								 or not cross by indicating a red/green bounding box around the pedestrians.
								 As far as the ego vehicle is concerned, the intention of pedestrians in the
								  immediate vicinity or the path of the vehicles are of importance, whereas other 
								  pedestrians in the scene are not important (hence their bounding box colors should 
								  be green for most of the scene duration). The model's input is the live video feed 
								  from the front camera after which the object detector (YOLOv3) dissects the video 
								  into frames and tries to localize the objects of interest (pedestrian in our case) 
								  in each frame by plotting bounding boxes around them. After this stage, the detected 
								  pedestrians in the video are tracked with the help of an object tracker (SORT) 
								  resulting in unique IDs for each pedestrian in the video. Finally the detected and 
								  tracked pedestrians from each frame are gathered as features for the 3D scene classifier 
								  (DenseNet). The classifier uses the information of each pedestrian in the video to predict 
								  their intention to cross, ultimately resulting in a green bounding box for non-crossing 
								  pedestrian and red bounding boxes for crossing pedestrians.</br></br>

								The challenge here was to predict the intention at least 
								0.5 secs before the intended action occurred, which from 
								a safety perspective was required for the car to make any necessary decision.</br></br>

								Our teams took this basic framework and experimented with 
								alternate types for each component of the model such as SORT, 
								DeepSORT, Pose-Estimation based detection, and tracking. Similarly, 
								alternate types for classifiers such as Recurrent Neural Networks, Random Forest,
								 and DenseNets. Finally we tried feature engineering for the DenseNet 
								 classifier which initially used only the cropped pedestrian images as 
								 features. In this feature engineering we applied skeletons for the pedestrian 
								 using Pose-Estimator and retrained the classifier resulting in an improved AP 
								 score of 0.89 achieving more than the research paper that we started with. Thus 
								 using this new classifier and additional feature engineering we arrived at a better 
								 model for the intent prediction that predicts 0.5 secs before the intended action occurs.</br></br>

								
								</p>
						</section>
						
						

			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/moraldeepsingh/" class="icon brands fa-linkedin"><span class="label">Dribbble</span></a></li>
						<li><a href="https://github.com/Moraldeepsingh" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="https://cal.berkeley.edu/moraldeep" class="icon solid fa-university"><span class="label">Cal Profile</span></a></li>
						<li><a href="moraldeepsingh@berkeley.edu" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Moraldeep</li><li>Designed using: <a href="#">HTML5 </a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>